---
title: 每日学习问答笔记
date: 2022-11-4 12:30:12
categories:
  - slam
  - 理论学习
tags:
  - slam学习笔记
---

# 每日学习笔记

## 222-11-3

```
Q: 关于slam重定位的讨论
A: 使用粒子滤波时通过增加历史权重的方式获得一定scan的历史信息,当信息量达到一定程度时,开始做匹配重定位,最后留下一个pose作为最终定位pose,但实际上这种通过增加历史权重的方式获得历史信息的方式依旧会损失很多scan信息,所以可以通过scan叠加图后通过叠成更大图的方式最后进行匹配,尽可能保留scan数据
```

```
问题起因: 当厂家给我们传感器误差时的意思实际上就是说他们的传感器可以近似拟合高斯分布
Q1: 为什么可以拟合成高斯分布?
A1: 因为没有办法,只有高斯分布可以在传播过程中依然保持高斯分布,这种特性是其他分布所没有的,只能如此,所以这也就导致了这样一个问题,我们虽然拟合成高斯分布,但实际上传感器误差不可能仅仅遵循高斯分布,因此可以短期相信高斯分布的结果,但不可能完全相信它
Q2: 考虑amcl中观测模型求解权重的情况,为什么其似然域模型可以包含随机误差与最大误差的影响
A2: 因为这里的权重模型仅考虑单次本轮内比较,并不存在与下一轮或者上一轮比较的情况,因此可以用
Q3: 为什么似然域模型需要将p *= p; 换成 p += qz*qz*qz; ?
A3: 因为发现原有公式算出来的差距过于大,对于计算机并不友好,所以换种方式降低这种差距
```

## 2022-11-4

```
Q:关于长走廊与隧道问题
A:
1. 其观测协方差矩阵并不会发生变化,原因由于,特征匹配出现的问题,拿icp举例,两个在长走廊上的icp匹配可能得到的d_pose非常小,原因实际上就是选取的特征点存在问题,比如将其换成带信息的二维码则不会存在这样的问题
2. 为此可以判断处于长走廊,比如,通过法向量或者提线判断,最终决定于你对于长走廊的定义
3. 为弥补这种特征退化造成的影响,可能需要其他传感器的辅助(odom, imu)
```

```
Q: 关于法向量的思考
A: 可以通过scan.points[i]左右两个点进行叠加选择计算我的切线方向(甚至与可以通过所有的点进行拟合),从而求出相对于我车体的法向量
```

```
Q: 对于scantomap中map的理解
A: 实际上就是所有scan的信息整合,不过这里的map相当于所有scan进行了一次降采样,一方面过滤掉了一部分scan坏的点另一部分也减少了总体scan的信息量
```

```
Q: 简述说明icp过程?
A: 1. 搜索最近点 2. 获得点对 3. 最小二乘迭代 4. 评估icp匹配质量(这里通过匹配点对/scan.size, 但实际上这只是一种无奈操作,我无法判断是80/100更好, 还是160/200更好)
```

```
Q1: 简述ndt过程?
A1: 1. 构建ndt栅格 2. 计算每一个ndt栅格左边与协方差  3. 通过协方差加权最小二乘迭代 4. 评估匹配质量  
Q2: 思考ndt与icp区别?
A2: ndt本质上是从icp衍生而来,只不过为了简化计算量,将前一个scan做了预处理,然后通过加权最小二乘实现迭代
```

```
Q: 思考GPS,反光板,二维码与land_mark在图优化中的作用
A: 提供绝对约束,或者一元边
```

```
Q: 思考图优化中滑窗与边缘化
A: 边缘化的概念是希望删除一些不需要的关键帧,但保留其约束,这样就可以与滑窗联系起来,通过滑窗将不需要的关键帧删除,这就势必舒尔补导致将原有的稀疏矩阵变为稠密矩阵,而vins的做法是保持信息矩阵维持在比较合理的尺寸
```

## 2022-11-5

```
Q: 关于重定位与slam关系思考
A: 可以将slam想成前端重定位作为后端两个线程
--------------->slam线程---------->重定位线程(类似于后端优化线程)------------------->ret(pose, map)
				  pose|map
SmallRelocate|FastRelocate|DynamicRelocate|Mapping
					slam
```

```
Q: 多线程数据传输
A: 可以通过跨线程类传输数据,比如

class Map2d
{
public:
	GetCellValue()
	{
	 	lock(m_lock);
	 	// do something.....
	 	unlock(m_lock);
	}

	SetCellValue()
	{
		lock(m_lock);
	 	// do something.....
	 	unlock(m_lock);
	}
private:
	mutex m_lock;
};

int main()
{
	Map2D map;
	slam Thread(&map);
	Relocate Thread(&map);
}
```

## 2022-11-9

```
Q1: 在做最小二乘时,error做损失函数的目的是?
A1: 为了让训练模型的特征更容易达到我们所期望的效果,具体可参考:
https://www.bilibili.com/video/BV1vg411172u/?spm_id_from=333.337.search-card.all.click&vd_source=745fd1b1f3e42bb544237f6d0bf78bb2

Q2: g2o文件中信息矩阵为何要开方处理
A2: 由于g2o默认为符合高斯分布,因此可以通过高斯分布的损失函数求解,这里的开方的目的是方便处理,具体参考
https://github.com/alademm/micro-graph-optimizer
https://github.com/dongjing3309/minisam
```

## 2022-11-10

```
Q: 对于vector等STL与智能指针来讲,对于内存消耗与运行速度思考
A: 相较于最简单的数组,使用STL势必会占用更多的内存与时间,所有如果是非常频繁的使用尽量使用最简单表达
```

## 2022-11-11

```
Q1: 在进行QR稀疏矩阵求解或者Cholesky分解前由于矩阵为稠密矩阵,消耗非常大怎么办?
A1: 先通过近似最小度排序将稠密矩阵转为稀疏矩阵.

Q2: 为什么矩阵会变为稠密矩阵?
A2: 因为在回环检测后如果依旧在原有的路径上行走,会出现很多回环点,导致矩阵越来越稠密.
```

```
Q: Chou_Liu Tree理解?(可以理解为将稠密矩阵转化为稀疏矩阵的一种方式)
A: 目的是将联合概率分布转化为二维分布连乘形式(近似): 
	寻找一棵以互信息为权值、变量为节点的最大生成树作为依赖树
	参考: http://www.bewindoweb.com/232.html
		 https://zhuanlan.zhihu.com/p/437028454  
		 https://blog.csdn.net/qq_38023849/article/details/110306178?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166555644916782425127805%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=166555644916782425127805&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-3-110306178-null-null.142^v53^control_1,201^v3^control&utm_term=chow-liu%E6%A0%91&spm=1018.2226.3001.4187
		 https://blog.csdn.net/qq_35201208/article/details/126289355?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166555644916782425157603%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=166555644916782425157603&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-126289355-null-null.142^v53^control_1,201^v3^control&utm_term=chow-liu%E6%A0%91&spm=1018.2226.3001.4187
```

## 2022-11-16

```
Q: 对于map更新思考
A: 由于map整体上占用比较大,一般使用增量式更新,一方面便于自己使用,另一方面便于给显示使用
```

```
Q: 关于二维地图修正
A: 常规思路是提线,不过由于只是为了将地图摆正,所以只需要在地图范围下对其进行矫正(数格子,连在一块最多的格子,则认为是墙壁)
```

```
Q: 关于Eigen库稀疏矩阵使用
A: 一般操作是先将其储存在三角矩阵中最后通过稀疏化提取放入到我的稀疏矩阵中,具体可参考:
https://github.com/qixianyu-buaa/EigenChineseDocument/blob/master/Eigen/Chapter3_SparseLinearAlgebra/Section1_SparseMatrixManipulations.hpp
```

## 2022-11-17

```
Q1: 关于单层神经网络流程理解
A1: 总体上分为前向传播(输出分析结果)与后向传播(更新神经网络权重)
前向传播:
	1. 与权重点乘获得结果
	2. 归一化用于传播
后向传播:
	1. 计算误差
	2. 计算学习率(根据激活函数)
	3. 更新网络权重

Q1: 关于多层神经网络流程理解
A1: 总体上分为前向传播(输出分析结果)与后向传播(更新神经网络权重)
前向传播:
	1. 与权重点乘获得下层结果
	2. 归一化用于传播
后向传播:
	1. 计算上层误差
	2. 计算学习率(根据激活函数)
	3. 更新网络权重
```

```
Q: 数值最小二乘与最大似然估计相关性
A: 由于一般联合概率分布为多概率乘积形式,因此会先通过ln转换为连加,而根据正太分布可知,这两者本质上是相同的(最优化理论与基础)
```

[![zexLpq.png](https://s1.ax1x.com/2022/11/17/zexLpq.png)](https://imgse.com/i/zexLpq)

```
Q: 对数几率回归应用
A: 又称sigmoid函数,主要是在slam的mapping中使用,目的是将每个栅格值做归一化处理
	由于sigmiod的分布在0.5附近变化很大,所以也可以很快区分占用与空闲栅格
```

## 2022-11-28

```
Q1: 关于长廊导致的slam定位不准
A1: 首先明确的是slam定位不准并不是scan匹配问题,而是slam定位时选取的scan关键帧没有特殊性导致的,因此对于这种情况一般可以划分到slam定位异常处理:
	1, 通过形态学检测长廊
	2, 通过长廊特点(由于长廊状态下匹配得分必定非常相近),用于防止误判
	3, 调整采样模型
	4, 脱离异常状态的重匹配
```

```
Q2: slam对于异常状态处理
A2: 由于slam源于匹配必定会出现匹配断掉的情况,因此就需要对其做特殊处理,如(踢动, 脱困, 长廊等), 因此可以将其分为normal与innormal进行处理
```

## 2022-11-30

```
Q: 关于前后端思考
A: slam作为前端输出map与匹配pose -> 后端通过判断状态进入不同子状态,如动态重定位, 小定位, 纯slam等,这样就可以通过设计不同后端程序实现所有功能,可拓展性很强
```

```
Q: 思考为何可以通过多传感器融合解决长廊问题?
A: 并不一定,一般长廊会导致的是匹配失效,因此使用传感器的话可以通过反光板或者二维码可以提供绝对坐标,用于比较修正
```

```
Q: 对于多传感器融合思考
A: 多传感器融合时需要根据其特性设计不同的模型, 一般根据其精度确定主次关系
```

## 2022-12-02

```
Q: 关于廊道匹配问题再思考
A: 由于此时廊道匹配时不在相信平行于廊道方向的值,所以仅对垂直廊道方向做匹配,其本质还是在于采样算法思路,常规匹配时匹配范围较小,相信的可能性较高,而sos模式下,概率分布变化,误差椭圆变化,放大匹配范围,此时廊道也是一样,可以看作是它的误差椭圆发生变化,导致的平行于廊道方向的匹配没有意义,所以仅需要在垂直方向上做匹配就好.
```

## 2022-12-03

```
Q: slam架构重构
```

```
d_mapper:
	d_data_parse
		f_slam_data
		f_pose_manage
		
	d_slam_status_check
		f_status_check_main
 		d_normal
		d_tiled
		d_pure_odom
		d_...
		d_common
			d_scan_match
			d_tiny_icp
	d_mapping
		
f_mapper main: just interface
data parse -> slam status check -> data parse -> mapping
```

## 2022-12-05

```
Q: 关于优先级体现
A: 
std::vector<status> statuses;

status CheckStatus(scan)
{
	for(s : statuses)
	{
		if(s.Check())
			return s;
	}
}
```

## 2023-06-30

```
Q: 关于系统架构的简单理解
A: 系统架构的话, 以我理解, 我们需要考虑这几个方面, 任务系统, 逻辑调度, 任务实现 
例如: 
任务调度: 时间片轮询(可加入优先级)
逻辑调度: 状态机, bt树
任务实现: 根据不同任务具体实现(一般可以使用责任链模式)
```

## 2023-07-17

```
Q: 关于大场景叠图问题思考
A: 大场景叠图, 主要由于累积误差, 也即是马尔可夫过程(重点看一下)
    思考1: 为什么小场景下不会出现问题?
    原因: 由于传感器与场景构建成了绝对约束, 这个定位误差只会在传感器误差之内
    思考2: 为什么大场景会出现叠图?
    原因:: 在大场景下, 传感器与场景构无法构成绝对约束, 因此导致了这个约束会叠加, 类似于(0.9*0.9*0.9*...), 就会导致偏差越来越大
    思考3: 如何解决这个问题?
    方案: 思路, 构建传感器与场景的绝对约束, 让此约束使得定位在传感器精度以内
```